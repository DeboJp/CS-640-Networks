# Lecture 1:
    - Building blocks - nodes and links: links connect any 2 nodes.
        - Scaling problem (N2) wires(connections from all) or one wire(every connect to one) we dont do either: 
            we connect nodes to larger router, and routers are connected - more feasible.
        - Google Search: Host -> query -> internet -> Google Serives- runs on Hosts(Googles' Data centers, etc.)
            the arrows are communication links - a physical media that carries data.
            the internet is a network of networks: how to connect multiple hosts, we use routers and switches.
        ISP: Internet Service Providers - a vendor that offers internet connected services(ISPs talk to each other 
        as well and each handles a network of networks).
        
        Protocols: defines order and format of messages for communication between devices.  Things like encrypting, bits conversion, secure, etc.

        Computer network: A SYSTEM htat provides cross-host commpunication for info exchange.

        Design Reqs: connectivity, reasonable correctness(showing up to data version), reasonable Performance, Low cost, reasonable Security. (In order.)

    Whole picture: harware infra, protocols, TOOLS(CDNS, SDNs, middleboxes, caching)
        Infra: harware very old(old school building wires), but why internet still so fast?
        Protocol: navigating traffic, needs wholistic view, similar to maps.
        Performance: throw more infra resources to prolem(mb to gb, etc) + latency problems(artificial workers).
        Cost: low, Security: reasonable.
    Answer? Protocols solve all these?

    Lectures: physical layer, data link layer, IP layer, transport layer, Application (+Security)

# Lecture 2: Layering
    Serives(i.e. google): has client and server, client intiaties contact,reqeuest. server provides a service.

    What is a link exactly, DSL Home network, connects from home cable to telephone company with multiplexer(resrouse usage), given phone line or isp.
        - multiplexing - (1) time division time multiplexing, waits one and prioritizes other
                        (2) parallel multiplexing - frequency division multiplexing. uses a splitter 50 khz to 1mhz for 
                                                    downstream, 4khz to 50 khz for upstream, 0 to 4khz for two-way telephone.
                                                    (distance affects ignal, degree of electrical interference, about 24Mbps-52Mbps downstream)
    Cable link, multiple home cables are connected to a fiber node - a neighborhood junction that support tv signals and network (same concept, 
            freq division multiplexing, Every physical media introduces noise- media impairment, Tv 54 mhz to 500 mhz, network 54 mhz to 1ghz, 40mbps to 1.2gbps down, 30 mbps to 100 mbps up). 

    FTTH home network - Fiber to home, shared connection to company, sharing the cable itself but direct connection to home.

    5G Fixed Wireless - Ethernet - WIFI - 5G mobile network.

    Main idea: need to share resources(each person cannot get their own link), to bring down costs, by multiplexing, freq and wavelenght.

    Q: is the wired shared for cable and dsl as well or did they have their own connections?

    (History) Message Switching: used telegraph lines - could take in data from any direction and send in cardinal direction of destination(were placed in physical hotspots like paris).
                                    called store and forward operations - msgs were decoded, next hop in proper route after reading data.
              Circuit Switching(old analog telephones): Reservation based system, source first establishes a connection(to operator), then swich connections to another user physically. 
                                                            No one else could use the resource at the same time as you. Dedicated service, really reliable and fast performance.
                                                            cons: resource management, not scalable, brusty traffic-what if permanent circuit like facebook.
    Current internet - Packet Switching: Every msg is broken down to packets, break it down to ms intervals. each packet given a source and dest addr. 
                        Jobs of intermediary nodes to passy the packets along. Store and forward.
    Circuit vs Packet Switching - Circuit is predictable performance, low resoursce usage. Packet high utilization, simple but not best for 
                                    extreme reliability but good for bursty traffic.

    PacketSwitching - packets go through switches and routhers to dest. store look and forward devices, takes packets from input ports, looks where to send it, 
                        does some traffic management, queues into buffers and sends to outgoing ports. Needs to wait for entire packet before putting into buffer(limited capacity).
                        L = bits, R = device speed, 3 packets take 4L/R since 1st packet just waits at buffer(introduced 1 time delay).
                        Fixed sized buffer, SRAM static random access memory, fast but hard to scale.
                        Protocols fill in forwarding table, so routers is able to send packet to matching addr's port. also SRAM.

    Circutit: Reservation based. Packet: On-demand

    SOFTWARE PART: 1. Scalable data movement, 2. Reliable bits delivery, 3. Performance maximization, 4. Resource multiplexing, 5. Access control

    Scalability reqs: many users, diverse services/tech, components built by many companies, diverse ownership, mix/match. 
    Key idea some sort of protocol: for scalability between heterogeneous things.

    Solution: connects all services with an intermediate layer(standarized - to address heterogenity). allows new advancements above and below layer independently. all must agree to use it.

        OSI Protocol Stack(the intermediate layer) - Open systems interconnection model, each layer relies on services from layer below and exports services to above layer. interface 
            defines interaction with peer on other hosts - called protocols, standarized. Modules hire implementation layers can change without distrurbign other layers.
                    
            THE STACK: Physical: transmit bits. Data Link: Transmit frames. Network: route packages. Transport: send packets end2end. 
                        Session: how to tie flows together. presentation: byte ordering, security. Application: everything else.
            (Session and presentation not used a much today integrated into app layer, 7 stack becomes 5 stack)

# Lecture 3: Layering + Performance Analysis
    life of packet: host (goes down stack from app to phy) -> Bridge/Switch(physical,data,physical) -> Gateway/Router(phy,data,network,data,physical) -> Host again(up the stack)
    
    a way to make structure for layer is specifying header.
    - each layer is adding some info or implemting their own protocol. (html, connection ID, source/Dest, Link addr <- at each layer)
    - top down from sending side, bottom up from recieveing side.
    - bits, frame, segment, datagram, message are the info the layers take or add, for respective phy, link, network, transport, app layer. Called encapsulation and Decapsulation.

    multiplexing and demux - there may be multikple implementations of each layer.
        - each header includes a demultiplexing field that is used to identify the next layer, filled in my sender and used in reciever.
        - multiplexing occurs at multiple layers.

    App layer example, 
        - Muliple clients ports in user space exits through socket API(attach socket to a cetain port number is the idea), TCP and IP in Kernel Space, Ethernet adapter in hardware. 
        - Same thing back up on serverside to single server.
    
    OSI/TCP Stack is an hourglass model. Because the intermediay layer is just 1 for internet layer, IP.

        - IP based on minimalist approach - DUMB NETWORK, switches, routers, just do store lookup and forward; routing, addressing, forwarding.
        - Transport layer and application layer controls more sophistacated(correctiness, congestion control, etc.) functionalities. - main job of internet is to pass things along.

        Advantages: accomodate heterogeneous tech(ethernet, wireless, satelline), support diverse apps(web, windows, ftp, telnet), decentralized network administration.
    
    Performance Analysis:
        Processing delay(sram access delay, string match for addr delay, etc.), queing delay (buffer delays in queue, time to wait to be transmitted),
        Transmission Delay (time to put info onto comms ports - port/transmission/link wire speed), Propagation Delay (time requred to propagate(wire to end host) over comms link.)
        Per node is also called total nodal delay, latency.

        Prop vs transmission delays: (propagation delay doesnt matter in close distance(but matters in long distance), transmisssion delays matter always).

        Round trip time, RTT: 2x one way latency ideally, but not always symmetric, the paths and latencies might not be same.
        Throughput: how many bits per second across 2 points in a network(file size/tranfer time), can only be min(or less) of two path speeds(input/output from switch/router), bottleneck.

        Total percieved delay = initial delay(how long it takes first packet to get from point a to b) + avg sustained throughput(Size/Data Rate).

            Throughput Sensive vs Delay/Latency Limited: if size is small/pings we are dominatied by latency(initial RTT), massive packets are dominated by avg sustained throughput. 
            - Applicatiion(data size) Dependent.

            - definitions of thoughput differs from layers and intent: 
                Can be application layer only data, app + headers, different headers, how measurements are done/load, how many flows(1-1 or 1-100), packet rate for data generation, etc.
                - retransmissions for dropped packets, first data measure or multiple, etc.
                The 4 delays are fixed though: the processing, queing, transmission, propagation delays.
        
            Bandwidth Delay Product: 
                Bandwidth: number of bits that can be sent instanteously, the circumference area of pipe.
                Delay - Length of pipe
                BDP: volume of pipe, the max number of bits that can transpit though pipe at given instant.
            
                RTT x Bandwidth = can approximate how much data we can pump into pipe and when to expect the data, to send + get confirmation.
                    - we pump data and if we get error we chaange, we dont send an initial packet and if it works we send(too slow i think).

                Network Tools, On Terminal:
                    traceroute (ip/DNS puclic address) - shows all route (might be blocked by ISP,spectrum, etc.)
                    ping (public website) - shows ping rates
                    netstat - all the tcp flows that are active, address, active, etc.
                    IFCONFIG?
                    sudo tcdump - allows you to acess packets at whatever fidelity, inpect network traffic (Wireshark open source analysis tool)
                
# LECTURE 4: Physical Layer
    Analog vs digital: analog takes continnous vals(sounds,images, etc.), digital takes discrete(texts, data, ex.), can convert bwt them.
        - analog data can be distorted when sent over network. digital easier, just checks between 0s and 1s. (if long distance data is still distorted, but we place regenerators to reamplify signal-to first sent like)
    digital nowadays: everything is a common abstraction towards bitstream. advantageous to be on single network.

    Modulation fundamentals(amplitude, feq, phase): bitstream over different mediams. ways to modulated waves, AM, PM,FM, amplitude Modulation, freq mod, phase mod (look into images to understand differences).         
        - does not have to be binary, can be muti-valued.

    Channel characterization(bandwidth,BER,SNR): how fast can we make perofrmance at bit stream level. can introduce, noise, attenuation, etc.
        - Bandwidth is the width of the freqncy range in which the fourier transform of the signal is non-zero. 
        (given any time signal, can convert to any number of feq sinosidual waves sum of which will be the orig time signal)
            doing this gives spectrum or freqency data, that allows us to measure bandwidth.(99% of energy seen on data amplitude, various scales(power,log)) db is half power, some scale.

        - Transmission Considerations ( Fundamental Limits: Nyquist limit, shannon limits)
            Limits: random energy (noise) always added to signal. Attenuation: some egery leaks away. Dispersion: attenuation + propagaion speed are freq dept(changes the shape of signal).
                - effects limit the data rate chanel can sustain, affects differnet trech in diff ways.
                - effects befome worse with distance. tradeoff between data rate and distance.
        
            Pulse transmission rate - channels turns digital signal to pulse(slightly spread out analog like shapes) Wc is the 99% of channel freq content. Up to 1-2Wc we can transmit without issues.
                if mlti level , 2^M amplitude levels bit rate = 2mWc(bit/pulse * 2Wc) bps, binary pulses bit rrate = 2Wc bps.

            Noise and Reliable Comms: physical systems have noise. create error, we report it though bit error rate (BER).
                SNR: signal to noise ratio, higher signal compared to noise = higher avg signal power. higher SNR = less errors. SNR decides if bit will be properly flipped when received.
                Nyquist limit - upper bound you can send through channel ideally. can past limit with multi-valued symbols, but SNR will ultimately decide limit. 
                    - Maximum possible capacity any noisy channel can supoprt: Capacity-bps, bandwith-hz, S/N-SNR, C = B * Log2(1+S/N) Shannons theorem. no one been able to do better than this.
                
                transmission rate(R) < C = arbitarily reliable comms is possible. R > C, then arb reliable comms is not possible.
                arb reliable means the BER can be made arb small though sufficiently complex coding.

            Bandpass channels: frequency centered at an fc point on wireless mediums(left is wc/2, same right), called carrier frequency. allows radios, telephones, and dsl models(not for wired).

# LECTURE 5: Physical Layer
    Digital Modulation 
        Baseband mod: send the bare signal - copper media, low feq(typically at 0 Hz).
        Carrier mod: use the signal to mod a higher feq signal, called a carerr. can send the signl in a particular particular part of the spectrum, i.e. wireless, radios, etc. (need to make space and move around freq channel.)
            how to do: amplitude career modulation, multiply digital voltage signal with career frequency to shift signal left or right on GHz channel, typical signal take small chunks in mHz. Creates twice the bandwidth, since mirrors on negative direction of shift as well.
            Implication of Carrier mod: Bandpass channel has bandwidth Wc, but due to mirror only 1/2 is useful. syetm suupports Wc but baseband challen has Wc/2 Hz available.
            Pros: idfferent users can use differnts part of channel, also known as frequency division multiplexing, though carreir modulation. (can be done by freq mod,phase mod, etc. - define fc,ft as locations)
        Demodualate-recover, by multiplying by 2cos(2pifct) for T seconds and low pass filtering(smoothing) - grabs the baseband signal discernable(from modulated carrer or baseband), and grab individual bitstream.
    line coding(wired): 
        Synchronizations of clocks in transmitters and recievers: but clock drift causes a loss of synchronization over a perod of time, even if both agree to freq due to hardware limitations. (True for wireless as well.)
        Asynchronous Transmission: 
            encoding converts binary to info seq into digital signal, sendedr then uses the digital signal tomodulate the sggnal in a way the reciever can recognize:
                - why need: synchronization issues, bit flips: error detection and correction, control symbols: start of end of bit seq/frame, electrical limits: avoid long seqs of ones or zeros.(all can be addressed via encoding - typically 1 level before phase feq/modulation)
            Line coding tech: 
                    naive Manchester Encoder: send both data and clock directions. issue: 2x electrical switches per bit. wasting two bits to send 1 bit of info.  (Also known as 1b/2b encoding, generall good no drift but inefficient)
                    Non Return to Zero: holds if same bit. sync loss due to lng seq of 1s or 0s, volt and clock can difts
                    NonReturn to Zero: every 1 switch, 0s holds sequence, sync loss due to long seq of 0s, increases number of electrcal switches per bit.

                    mBnB Encoding, m data bits are coded as symbols of n line bits(i.e. 4B5B - encode all 4 bits combinations to 5 bits that avoid long seqs and unique: can use 5bits, adv of clock drift and vold drift over time). Q: is it similar to manchester encoding?
                        gigabit over fiber uses - 8B/10B, 10Gigabit - 64B/66B.
    error control:
        workflow: (FEC - forward error correction)
            Transmitter: Bits to Fec to mod to signal.
            Reciever: signal to demod to fec to bits.
        Error Control: challens intro errors in digital comms, applications require certain reliability.
            ensures data stream is transmitted to certain level of accuracy despite rrors.
            two approaches: error retection and Retransmission(ARQ - resending data), Forward error correction(FEC - add extra data to correct as data psses along)
            can be done at multiple layer - wifi phy layer perform conv coding, etc.

        Key idea: data transmitted in blocks(codeblocks) to satisfy a pattern, no pattern then error. 
            can add extra bits to carry over info.
        
        Single Parity Check:
            - append a parity to k info bits, all codewords have even # of 1s. All eroors that create odd 1s are detectable as errors.
            - but if two flips happen, cannot detect. 
            Q: we are saying we can detect odd bit flips, what about more than 3 flips how to check/know? ignore?
                - just able to detect some i believe that become odd. even not detectable or even+odd just detects an error.
        
            - redundancy: some overhead to add bit.
            - all patterns with odd # of errors can be detected.
            - randon bit errors: many transmissions channels introduce bit errors at random indep of each other with some prob.
                we grab joint probabilities, if channel has p>=0.5 not worth wile to send over channel.
                Undetectable error: when even bit fits. n choose 4. number of other flips likelyhood gets smaller as it increases.

        what is good code? map by distance codewrods, if multiple valid/non-codewords codewords distributed somewhat uniformly its good, clustered of one kind might be getting confused.
            2D parity checks: we use row/col sums to detect, in number of 1s in row/col are even no error, odd errors?. 1,2,3 bit, errors can always be detected but patterns >4 can not be detected. 1bit errors can be detected and even corrected.
                check every rows and columns to see if count of 1s even or odd. then check if right and bottoms intersection is both odd, then error?
                cannot localize, just detect there is an error.
        checksum over intenet: to see calculation is equa to zero, can use modulo arithmetic but also binary.
    
    Q: confused about checksum, 2D checks, 1 bit detectable how if >2- just probability?
        - prob for how many bits are flipped.
        - checksum below
        - 2d checks if parity of extra row/col added at the end shows odd, then error. 1,2,3 detectable, 1 fixable. 

# LECTURE 6: 
    Other Error Detection Codes:
        Internet Checksum - inject known pattern, i.e. sequence even or sum of bits is 0, etc. for our case I.C. makes sum of bits is 0 by injecting an extra bit.
            checksum -*(adds all bits) mod (2^16 -1). add this back all bits, and sum mod 2^16 -1 should be 0. bit flips errorrs dont correct checksum.

        Cyclic redundancy Chekc(CRC) - for error detection though polynomial algebra.

        Repetition Code - Error correction code. sed repeated times and detection and correction by majority vote.
            High redundancy. adv codes(similar alts) - hamming, reed solomon, convolution codes, etc.

    QA Touch Base of past topics.
        - low pass filter, reduce freq of data, high pass allow more data to pass
        - bandpass channel, pass only a part of data, bandpass neg filter - take out a bandpass chunk of data.
        - rest edited into above notes.

    DataLink Layer:
        4 concepts - framing, switching, medium access control, reliable transmission.

        Frames:
            how we break up a stream of bits to frames(packets for higher level): a preamble + postamble (start/end token) + body.
            no minimum-can send smalle frames, but max above which need to be broken into multiple frames.

            Tech 1: Byte stuffing: sync markers, start header and start of text in preamble, postable end of text, checksum.
                sync markers might endin body, use escape character.
            Tech 2: Byte Counting: include a bute found and frame class in preamble to verify count in body if it matches. no start or end text marker.
                - but if counter bit is wrong-bitflip error, count wrong. checksum can detect and say if wrong though.
            Tech 3: Bit Stuffing: have a beg seq befor eheader, and end seq after crc. 
                add 0 for every 5 1's in body. receiver knows to see this pattern.
            Q: but how would we know if the seq had 5 origianlly or not? and how to detect ending, wont it just add 0?
                 - i supposed for end its after crc, so it would expect it after crc.
                 - count per bit sequence should be extra bits if bit 0 stuffed. (padding added in general to handle extra bits)

            
# LECTURE 7: DataLink Layer (Continued)

    Switching:
        ethernet - wired computer network technology.
        ethernet framing - does its own thing, preamble 8 bytes - separate technique than we studied. then eth Frame, then checksum(4b) at end. (error control happens everywere, data, physical, app, etc.)
            mac address - media access control 
            (6b and 6b for source and dest addr)
            type field (2b) used by payload follows, type specifies protol like ipv4
        switch has 2 stacks - max ability it can pass the data, is the data link layer. (has ports, addr lookup, traffic manager, que/buffer)
        table - if no match for addr will broadcast on all ports(except ones its coming from) - uses source addr and port so populates table. to make addr and port connections.
                - after tablel fill might be able to grab success hits. Only stores/looks up and forward.
                - ports just tell what is the next hops not final seq.
        switches need whole frame to come along.- classical
        cut-through switchnig - doesnt wait, if dest comes through and very low errors just pass it though.

        L2 Switching - enables scaling. 
        
        Forwarding Loop - waste when frames stuck in a look when trying to find sourceinit/dest.

        Spanning Tree Protocol(SPT) - convert cyclic graphs to trees. elect single switch as root switch. then travel to root then there is path to everywhere.
            - states kept at switch, another table(which know only their ids)
            - create a configuration message, to populate(imagine flood fill), root id, local id and distance to root. Keep issued periodically since things can happen(data lost, system down, etc.)
            - all switches when they start will think they are the root.
            (Switch operation assigns which switch has what id)
            - ACtions when recieve message - figure lowest number i.e.1 to assign root. communicate and find broadcast yes direction 
                - 2nd challenge path determination: resolve tiebreaks, make distance smaller, find root, disgrad everything else if not root. (most redundance link/edge/fartest connection determined though tiebreaker cut off - ports disables)
                    (i.e. switch 2 gets msg from sw1, finds sw1 id is less, adds dist +1 and stores with port number which it came from. if optimistic then broadcasts)
            
# LECTURE 8: DataLink Continued

    Medium Access:
        Schedule Access: schedle frame transmissions to avoid collisoins in shared medium.
            Pros:enhance fairness, more efficient channel utilization, less variable.
            Con: increaded procedural complexity.

            can be run in centralized system or distributed system, to determine transmission order.

            we run in reservation cycles, if hosts ones to send data they ask for permission and get a slot, called reserved interval.
                - some wastage but wokrs, slots found though time division multiplexing and hosts reserved as such, depends on algo single frame or multi frame reservation.
                - another way is random access reservation.

        Random access:
            same againa, shared medidum, we all trying to share resources.

            detec collisions and recover from collision, via delayed retry. data not sent at the same time to avoid collisison.
                Aloha(wireless): radio based comms, whenevr ready transmit, recieverrs send ack back. if ack never recieved/send, we just retry with random delay to avoid collisions. if ack gottem move on next packet.
                    - large collisions: then delay based on num of users. i.e. small if small users, vice versa. - too short
                    - too long - underutilized.
                    count total num of packets arrived at a time - use binom? mean = np, mean num of packets you can get in a certain amt of time.
                        poisson dist approx to binom dist ** when np is fixed ** and n is large or very small. (event counting process. need lambda/rate(in fixed time and independent))
                            can go from pdf to cdf dist using integral and back with differentiation.
                            if we know inter-arrival time between two process/events, we can convert it to number of collisions - probability of seeing how much of a time delay. to get individual time frames within that time frames, we differenciate and distibution becomes exponential(satisfies memoryless property).
                            othe property - if there n clients, each can have their own generation rate then go into medium. just an addition operaion on lambda.
                    vulnerability: any two packets , packed before and after so 2m duration that vulnerable, just retransmit over air.
                    Analysis: S is total amt of data we want to get through, G different arrival rate every time(load on system). We define success we in 2m there is no arrival. Max throughput, Ge^-2G.
                Ethernet MAC(ethernet): ...(later Lecture)

# LECTURE 9: DataLink Continued
                Slotted aloha: (assumed all devices share notion of time/clock/synchronize) assumed all devices designated slots, if collisions they retry with another slot, until successful.
                    vulnerability period is just M now. max they can collide in M interval/time duration, since they have same idea of time(slots). Throughupt = S = Ge^-G
                    higher throughput than pure Aloha, but takes a longer time, larger load on system, some latency due to fixed slot sizes.

                Ethernet MAC(Wired Medium): carrier sense: listen before you talk(CarrierSense), listen if someone else is using it, avoid collosion with active transmission.
                    You can also listen while you transmit(CarrierDetection), no need to wait for acks. only needs to listen to narrow range of powers compared to wireless which needs to listen to wide range/orders of magnitude.
                        if detect someone is tranmitting causing collision(both/all), then jam channel and stop, with backofffs(small if less clients, more if many) to retry. after a while if it doesnt transmit, Discard packet.
                    packets must be long enough to gurattee all nodes observe collision(and can jam if necessary - too short kinda useless/breaks algo). min packet length > 2x max propagaion delay.
                    Ethernet not based CSMA/CD no longer done, due to duplex capability(worst case for conflict if two would want to share wire, and there is two parallel wires so never happens). Wireless still uses variations of Aloha. 
    Reliable Transmission:
        reciever sends acks for each frame recieved, with identifier so sender knows whcih was recieved and now.
        frame missing? dropped while sending, or while sent back, or if reciever drops it. so need to retry after certain after time.
            sometimes reduce flow so other people dont drop packets.
        Technique 1: Stop and Wait. send msg out and wait to hear back if act. if ack gotten we know reciever is able ot recieve at this pact. if not, many reason(slow,etc) retry again later.
            if fast reciever, smaller timeout periods. can sometimes give duplciated acks if too fast reciever, but not a problem.
            cons: a lot of waiting, cannot fully utilize bandwidth, but easy to implement.
            idea to fix: send streams of data instead of single packet, and adjust accordingly.

# LECTURE 10: Datalink + IP Layer
        Technique 2: sliding window, windows of continous frames, best cases - all delivered and get acks for all windows. avg: 7 delivered and 3 not(retry for 3), but still thoughput is good since ew didnt have to wait.
        sender: has to maintain state: window size(SWS), LAR: last ack recieved(LAR), last frame number sent(LFS)
        reciever: has similar state: RWS-recieve winodw size(largesta acceptable window else simply drop since too fast), LAF-seq of largest acceptable frame, LFR-seq num of last frame recieved
            accpet frames only if less than end of window/LAF, and accept LFR +RWS.  if LFR>RWS discard frame and don send ack. (similar idea for sender)
        acks are recieved per frame not window. 

    IP/Network Layer: Efficient addressing, routing, inter domain routing, (NAT,IPv6,Multicast)
        switched local area network: connect several local networks to scale. how- interNetworking

        interNetworking: an arbitary collction of networks connected 
        Interent Protocol - run over all entities in a collection of networks, define infra that allows all to work as a single logical network. everyone agreed on a standard.
            also known as hourglass model.
            Best effort networking: use unified header format, support heterogeneous ntworks, provide unreliable packet delivery.
                header: version, HLen(header length), TOS(terms of service: tells method being followed), length, identification, flags+offset, TTL(tile to live), Protocol(demultiplex key i.e. TCP=6, UDP=17), Checksum, Sourde addr, destination addr.
                adapt ip datagram to underlying L2 farme: fragmentation and reassembly or synchronize
                    Frag and reassem: idea break IP data gram when traversing a link based on the small sized MTU. 
                        Strategies - idea breakkdown ip datagram when traversing link based on small sized MTU.
                            bread down datagram when necessary , avoid fragmentation at source, refragment the datagram if ppossible, delay reassembly until destination, do not recover from lost fragments(ask full retransmit instead of just lost fragment).
                            happens on need by need basis in the network entity.
                            can put flag saying dont fragment, or more fragments, etc. and specify th offset of fragment relative to beginnign so later know how to stitch, same packet number thats how we know same packet.

                    synchronize MTU: source tries to figuire out min mtu on path.send small msg, plz do not fragment to on. just drops bigger packets, sends ICMP to source saying error MTU exceeded. 
                        originally Ipv4, IPv6 delegates it to end hosts. 
                        if paths dont change, and query for ICMP msg.
                        Icmp - supporting protocol for IP to handle any errors, report status to source host so it can react accordingly.

                Unreliable Packet delivery: no gurantee of how data is transmitted, lost, delivered out of order, duplicated, etc. above layers handle it.
                    
                L3 can create new ethernet frames(i.e.in fragmentation), L2 can only lookup and forward.
                    in L3 for new frames - source and dest same but MAC addr changes(MAC of router used for next hop).

    Packets are also called datagrams

# LECTURE 11: IP/Network Layer
    Forwarding/swtitchinig - taking input to output after looking at routing table.
        Delays: processing, queing, transmission, propagation.
    Routing - routers optimizes processing dealay in hardware makes it fast.
        determines end to end paths, implemented in software.
        implemented in L3, switches source if switch passes though,
        Delays: same delays.
    
    Efficient Addressing:
        ip addrs - defferentiate communication entities, determine how data is transmitted, impact the network scalability.
        ip addr is owned by an interface(every interface can have multiple ports). 
        every interface has its own Ip address.
        
        Dotteded decinal notation: an ipv4 address has 32 bits - 4 billion unique addresses. 
        Five IP CLASS:
            Class A address - 0,can have 2^7 networks, but can have many hosts
            B address - 1,0, can have 2^14 networks, lesser hosts.
            C addr - 1,1,0,can have 2^21 small netowrks, 8 hosts very small.
            Class D - multicast, reserved for multicasting, send to a group of ip address from one source.
            Class E - more experimental/research/dev.
            (all class networks are taken), each class has a 0,1,1s(diff size for each class) can they are matched with router with prefix matching, insteading of direct/complete matching.

            Classful Addressing is inefficient - 
                address waste, class C with 2 hosts 0.78% efficiency, but clas B with 257 hosts efficiency 0.39% efficiency
                still too many netowrks = routing tables become expensive that cannot scale(too many rows in table even though its 2^7 + 2^14 + 2^21), route prop protocols dont scale.
            
            Subnetting(Class B) - add another addr hierarchy, the subnet masks(just 1's to make prefix matching easy - if arbitary mask cannot use prefix matching) makes network much more flexible(to give number of host devices).
                - instead of neeting 3 classes for each organization. all organizations can operate in their own network/subnets, with the same class network.
                - perform bitwise and host number + mask to get which how many data(to get subnet number).
                mast last number is 128 and sunet is 0, hosts can ahve 0-127 address(at the very end.)
                    if both 128, then 12-255
                    last bit addr always left for broadcasting.
                can use slash numbers /24 to freeze for only 24 address for hosts.

            Supernetting(Class C) - enable network to be any length, collapse multile addr assigned to a single entityy, assign block of continous network numbers to nearby networks.

            CIDR - Classless mechanism to make t more free. Breaks rigit boundareis between addr classes, combine subnetting and supernetting.
                - first 16 bits still frozen, + 4 as well sice next 4 aways stay at 1, total 20. 2^12 address are possible.
                - idea is aggregating class C address.
                Can use CIDR for trad networks as well, by /8,/16,/24 to freeze first few addrs, and they act like classes again.

            IP vs Mac
                Mac; physical harware addres not made for routiing, given by manufacturer(if something falls in local area network, then useful - to send frame to address since switch can see.).
                IP - can used for routing.
            
            ARP protocol - each hosts has a map between mac and ip. to communicate with hosts on same switch network, each host needs to know the desk mac address. 
                routers also ARP from time to time, if fdest host is on same subnet then use its MAC from ARP cache,e sle forward to next IP addr hop.
                table contents learned using arp protocol, and cached when updated.
                Otherwise, routing only cares about IP, switch no concept of IP so need to know. routers cares about mac to match local.
            
            How to assign ip address: 
                Technique 1: Manual Config(static ip) - add ip addr with this mask to this host. (ip a add 192.168.1.100/255.255.255.0 dev eth0)
                    drawbacks manually for all hosts, easy to make mistakes.
                
                Technique 2: DHCP(dynamic host config protocol) - a dedicated service for assigning IP for each admin domain
                    a dhcp server maintains a pool of all available addresses. leases for IP are perodically updated.
                    Works - arriving client sends a special IP broadcast msg to the network, recipient for DHCP is always 67, msg that goes from client is DHCPDISCOVER. Transaction ID and machine addr helps server prevent assigning clashing addresses. 
                        DHCP Offer - server sends out of src 67 to 68 broadcasting(all 255), and DHCP server ID, and lifetime offer(need to accept in 1hr for ex) for client to accept. machine address used to see if host should accept, everyone sees messages.
                        DHCP request - client makes a decision.
                        DHCP ACk now client has that address (but dhcp sitll broadcasts since it doesnt know for sure - small packet not a burden on network/to avoid issues if something goes wrong). (Total 4 steps.)

# LECTURE 12: Routing
    to populate routing table only need subnet number and subnet mask - know if dest inside or outside subnet.
        every row has subnetnum, subnetmask, nexthop. dest+subnetmask if same as subnetnumber then prob within subnet/send to router or hop to next.
    routing challenges - network traffic is dynamic, they only know neighbors no full picture.
    native approach - static(can appear and dissapear) config,, calc path manually fill routing table. Drawbacks no adaptation, unable to scale.

    Distance vector routing algo/protocol: 
        assumption: key idea you know your neighbor, and cost of sending the data to your neighbor.
        key idea constructs 1D vetor that contains cost and distance, distribtues to neighbors. Distributed system.
        perodic cycle that happens. this communication adds weights for cost, for every dest and next hop from curr hop, so at the end every router knows how to get to destination. 
            in spirit similar to spanning tree algo. but msgs dont need to send all the way to dest, only to neighbors.
        reaches euqilibrium unless some node fails/deletes or added.
            slow converging issue to get to equilibrium for whole network. old data creates a negative  loop to infitey, simple fix, if it goes beyond a certain number just drop it.
        hard to do time sync with clock with such large graphs.

        Fist distance vector algo - Routing Info Protocol (RIP):
            udp packet to ports, freq = 30, if val reached more than 16 for our case we drop.
            earliest ip routing protocol.

# LECTURE 13: IP Layer: Routing(Continued)

    last lecture we talked one type of routing. Link statte more populat, relaxes assumption abt talking to neighbors, talk to whole. Each node has info of whole network. finds shortest path between two nodes.
        sending link state/condition of neighbors to neighbors, converges quickly under static conditions. sending raw conditions of your connections, all nodes have whoistic info, more efficient to propagate though network
    
    LINK STATE ROUTING:
        Reliable flooding(broadcasting)
            node sends link state to all directly connected, each node recieves and forwards it out to all its links.
            link state packet(LSP) includes, ID of node, cost of link to each directly connected, the seq number, time-to-live(TTL-decrements every forwardings, i.e. travel max of 64 hops) of this packet.
            reiability - decrement TTL while flooding. also age decreases in the LSP in its own table for each table, Discard the LSP when TTL becomes 0 or age too old(no updates in long time).
            each node gets image of network.
        route connection
            compute shortest(min cost) path between any two nodes i and j. from you to everybody else. dijkstras algorithm (a* theorreticlaly faster but not direction info for ip addresses-cant make heuristic algo other than cost minimization, algo only runs on local network for serity, pass to next router entry Gateway they do their own routing).
            protocol called - Open shorted path first(OSPF) header has version, type msg ength, source, areaid, (checksum ,auth type) both to avoid fake link state ad to propagate - sanity check if data is correct, auth, etc.
            LSP have - link state id, advertising router, cost of lists, seq number SEQ, TTL of packet, TOS - terms of service(router can use info to break ties custom coding i.e. use lower latency if costs were bandwidth only - i.e. ISP gave certain host max data for certain time only), LS seq number - general advertisement(always propagated - periodically send to avoid dropping + and -, bigger packet) or keep alive msg(tell neighbor still connected to avoid flooding, tiny packet).

            Link state Routiing - high messaging overhead, computing complexity
            Distance vector - slow convergence, race conditions

            Why link better? dijkstras(typically slower), ~ 1/2 packet size(but all needs to prop), drop off : main reason is pretty much the flooding idea.
            distance vector kinda like a tree waits for every node before it moves forward, LS more like flooding from each node simultaneously.

        Metrics for Link Costs- 1. number of hops, 2 link cost, latency and bandwidth - can use acks from rotuer to router to approx these.
            - arrival time - departure time + transmit + latency = approx delay, can use this as cost.
        Architecture:
            also is run in software not hardware, some seconds in convergence. prolly not update every LS ad update we use some specific condition to push updates.
                table in hardware. faster.

# LECTURE 14: Ip Layer: Inter Domain Routing

    two options for rouitng: distance vector and link state. (intra domain solutions - routing inside smaller domains)
    domain is an smaller organizatoin under the same admin control, refer to as Autonomous system(AS),16 to 32 bit unique number. every organizaison gets 1.
    (routing between domains, larger we wont be using these directly.)
    itra domain routing - how will route out of domain without table entries.   
        most routers are interanl within AS, some gateway routers connect to one or more routers in other AS - inlet/outlets to talk to other domain.
        if no mach in routing table send it to gateway router. it should be able to send it.
        internal msg - advertise the prefix reachability within an AS
        external msg - advertize prefix reachability outside an AS - prefix matching to find which AS might have x.

    BGP border gateway patrol
        eBGP distribute spanning neighbor two AS
        iBGP distribute interally
        runs of TCP

        route selection: next hop - ip adr the router interface that begins as path. as pact is the list of ASs though which advertisements has passed.
            entire path is being communicated in msg, concanating and passing it along differnt ASs. (differnt from intra, has entire path in msg.)
            after BGP, it see maybe 2 possible paths, we do hot potato routing(total len or hops to go to final dest). gives flexibility to AS to whatever selection it want to make.
            reality very complicated

    Autonomous System
        AS traffic types - local start or end within an AS, Transit pass though AS.

        Types 
        sub AS - has single connection to other AS carries local traffic only.
        multi homed As - has connections to more than one AS, refuse to carry transit traffic. (I.e. Large coperations - only sends trafic - neever advertise its capable of forwarding beyond consumers - might have two links for other reasons(scaling, redundancy, etc))
        transmit AS - has connections to more than one AS - carries both transmit and local. (weather or nto multihome or transit depends on policy configured, looks similar.)

        AS characteristics
            each has one or more border routers - handle inter AS traffic
            BGP speaker established sessionss with peers and advertises route info - path selection, reachability, etc. can have preferences like avoid AS10, etc - since have entire paths for selection.

            
    BGP works in TCP layer does not have to worry about IP lenght, but ip level still have to manage next hop level management.
    
    BGP how selecting best challenges
        internet size  means large tabels, 
        policy compliant pattsh, 
        different AS use different path metrics, 
        not inherent trust among As's.

    BGP policy: learn - import routing info from my neighbors, spreak - export routing infomrating to my neighbors. (i.e. avoid As's, impleemnt min cost, trottling internet speet, etc. - due to flexibility in polciy design in BGP)
        bgp provides the capcaity for reinforcing policies, policies not part of BGP they are provieded to BGP for routing config.
        peering relationship - are free with no cost, cusotmer provider relationship - customer pay providers to reach rest of internet. (typically prefer money, customer >peer> providers)

        peer relationship is free - only advertises to customers not provider or other peer. (only accept request from neighbors)
        provider - only advertises to customers not provider or other peer. ( accept any they pay, all customers-infrastrructure backbone for example(used to be gov, mostly now private))
        customer - advertises to all, obligated since they are paying.
    
    How to trust bgp backbone if there is a monopoly in market? things to think about.

# LECTURE 15: IP Layer: NAT, IPv6, Multicast.

    Nat - network address translation. - own private network. onlu up to 2^32?
        exposes whole subnetwork as one ipadress visible outisde, inside can have many hosts.
            goes to single router gateway, which converts source to public facing IP address; hosts dont know.
            gateway has a NAT table holds extra service port numbers(kinda like ID) - short time lived, non permanent. Can be used to uniquely identify hosts to public dest. - some hashing can be used(w/ entire uniqueIP). dedicating ports typically not a problem.
            cannot serve two server to public facing ipaddress easily is a limitation. ask question.

        Class A,B,C ranges is reserved for private use, can use anything else.

    Ipv6 - just a forward stream, does routing to scale, check sums to see if header is good else drops, no acks. Goes everything except addressibility.
        changes - 128bit address space(1500 addr per sq ft on earth. classless), 
            Qualiy of Serive - option to find better paths,latency, etc(replacement to TOS), 
            Security and auth - checksum package integrity but new only verified can recieve packets, 
            auto configuration - randomly sample ip adress conditioned on MAC addr  and use is (conflict is minimal - ipv4 was either manual or dhcp server) dhcp server implementaion also simple no need to maintail pool of address
            enhanced routing func - mobile hosts, avoids the need to backandfort reqs if moving from subnets, auto config makes it easier to just sample instead of nonstop comms with dhcp server.
                sampling idea is : prefix from dhcp server(dont assign ip addr), and we samle ip addr to use for our purposes.
            support efficient multicast - server wants one flow to reach group of clients.
            Rely on simple protocol extentions 
            Enable a smooth transition path from IPv4 - backcompatability to IPv4 to maintain the narrowwaist/hourglass idea.
            (series of 0's can be masked with ::, and slash structure from IPv4 still can be used)

        prefix - FF is multicast, 001 is uniast. host addr is combination of prefix(given by dhcp) and sample host identifer(bitwise addition), prefix aggregation is possible? a lot of empty categories, some represent ipv4 to ipv6(i.e. 0000...:ff:ipv4).
        
        provider base plans - internet is organized into hierarchy of networks, 3 levleel: region(ipv4 doesnt have this - it had organizations only)-helps with routing(ipv4 first frozen holy held class info, can help implement geographical routing i.e. A* better algos), provider, subscriber.
        Format - version, flow label(tell router focus more continous stream - router maintains state avoid switching, other stuff: latency, thoughput) and traffic class to specify TOS or Qos. Payload Lenght - length of data, Next header - how big will variable header, can add forward pointer to spcify fragmentation, security, TCP/UDP, etc.
            no checksums in header, too redundant, have reliable develivery in phsycial(bits), frames(mac) and CRC. more in app, and transport layer.
            by default no fragmentation and reassembly support.
        
        Transition - cant do terminate on single day and move on.
            dual stack operations - map ipv4 to ipv6 and keep runnign operations. today not very useful.
            Tunneling used to deal with networks wher IPV4 routers sit between two Ipv6 routers, encapsulate packets in Ipv4 format, until hit the next Ipv6 router. can go both ways. Ipv4 cannot by default support Ipv4 but thhough encapsulation can, without it just drops it.
    
    Multicast - One to many communication- video streaming like server flows to multiple hosts. routers support it too. Ipv4 had class D which supported multicast operation and always had first 3 1, rest were open to for gorups to use for multicast.
        idea send to multicast address and it will send to group you want to send it to. router neds to understand which goes to groups. maintains state
        Internet group management protocol - facilities the process of making groups, hosts indicate they want to join, router discovers, and implemented over IP. and sender verifies repicients on group, and sends.
        joining - R sends membership report request, designated router(DR) recieves it and shart forwarding, DR periodically checks if want membership or not. can leave same way. DR recieved multicast signal and sends to group. Need support from router, else cannot(will take the form of individual connections).
        
    Overall so far:
    ip layer - overall idea datagram delviery channel between hosts in any network under the best effort service model. Ipv6 is emerging, can do more, not widely adapted, BGP(routing protocol) provides extreme flexibility pay or not etc.
    link layer and phsycial layer typically combined in modern Architecture, but can be separated with intention.

# LECTURE 16: Transport Layer
    IP,Link,Physical - overall host to host communications between two end points.

    Transport layer bridges app and comms, though process to process communication.
        (most important) provides gurantee - pacter order, exact one copy, etc. bec IP only gives best attempt. so transport layer to gurantee if wanted.
        should support multiple app proc on a host(multiplexing)
        supports arbitary large messages, types, length, etc.
        limitations - fixed size socket buffer in OS.
            fixes sized data transmission unit in network
            computting and comms entities run at different speeds.

    UDP: user datagram protocol
        does not give you gurantee, is just best - effort, unreliable and unordered datagram service.
        can do multiplexing/demultiplexing.
        baremin reliability through optional checksum.(not unique, other layers also do it.)

        it does it through, demultiplexing key - port: servers have well known ports, can be short lived, mapped to perm ports, dynamically allocated as well.
            enables messages to be multiplexted to proper messages.
            ports are addrs on individual hosts not across the internet.
        
        ports are implemented as message queues, is interleaved across application - lifo, fifo, etc. implemenataion

        has headers - source port, destport(changes based on server, DNS, etc.), checksum, length(can do 65548 bytes and per app - IP layer deals with breakdowns if bottlenecks exists later on, etc.).
            checksums - only care about integrety, sum on header + data + pseudo header (protocol nuber,the IP source, dest - doubel checks kinda, IP layer does it too).
        
        minimum specification make UDP very flexible, an end to end protocol built atop the UDP. RPCs, most common multimedia application, latency(streaming apps), etc.
    
        best of both world TCP/UDP (Security TLS and TCP, order, latency) = quic protocol (70% of internet traffic uses it) implemented a layer just on top of UDP.

        no rate info, reliability of delivery, or variable in network bandwidth resources

        Issues: arbitary comms(any hosts can talk to others when they want - doesnt ask perm just sends/talking, can cause clashes, stale data exchange), no realiability gurantee(no acks,no order, packets can be lost, chcksum not enough), no resource management - rate of data, slowdown or speed up.

    TCP: two way reliable byte stream oriented protocl, TCP most widely used internet protocol, very closely tied to internet protocol (TP) - often called TCP IP layer.

        connection oriented - some time taken to establish connection. app writes in bytes to TCP layers. APPs read and write data in byes, TCP sends in segments.
        two way communication 
        resource management - keep senders from over-running the reciever, flow control. (flow control in Link layer is Optional - doing it in Transport layer is recommended.)
        congestion control - keep senders frmo over-running the network, adjust something like the window, adjust the rate, to not overwhem reciever, router, or other network agents, to ensure reliable delivery.

    Wireless scanners - Current progress and usage.
        imaging - wireless imaging in airport to see through clothes, instead of RGB in dark picks up data. extreme rain/fog leave RGB and move on wireless.
        sensing - non-line of sight of sensing, sense how much sweat on hand(intense or not, can see flow of blood flow, though head,etc.)
        comms/networking - managing large scale communication, i.e. sattelies and routers there.
    
# LECTURE 17: Transport Layer Connection Management - addressing UDP 1st issue.
    UDP  message-oriented  treats each message as an independent unit and sends it as is.
        - It cannot aggregate two messages because each UDP header includes a single source and destination port, and each port is bound to one process. Theres no mechanism to bundle multiple logical messages into one UDP datagram.
        - Its unwise to make datagrams too large, since oversized packets are more likely to be dropped later in transmission.
    in general Ports and sockets allow concurrent multiplexing, enabling multiple logical communication channels over the same network interface

    TCP dynamically creates and destroys a full-duplex communication channel between sender and receiver processes for reliable byte-stream exchange.        
        Data flows as a continuous byte stream in buffers. TCP divides this stream into chunks called segments, which are passed down to IP for transmission.
        To establish a connection, TCP uses a three-way handshake:
            The sender transmits a byte stream of SYN segment containing its starting sequence number.
            The receiver replies with a SYN-ACK containing its own starting sequence number.
            The sender acknowledges the receivers sequence number.
        Different starting sequence numbers are used to prevent old or delayed packets from previous connections (incarnation problem) from being mistaken as part of the current session. To mitigate this, sequence numbers are randomized, and connections are often kept in a TIME-WAIT state for 12 minutes before fully closing, allowing any straggling packets to expire, also allows us to recieve resent acks from server if ack dropped.
        Termination seq: The client sends a FIN marker indicating it has no more data to send.
            The server acknowledges the FIN and later sends its own FIN when its done transmitting.
            The client finally acknowledges that, completing a four-way handshake.
        4 steps instead of 3 because each direction of the connection (send/receive) must be closed independently, one side(client) might still need to accept delayed packets after signaling its own closure.
            (but what if both TCP connections want to terminate - corner case).
        In header flag decides where we look at - If SYN or FIN flags are set, the sequence number field is read., ACK ACK is set, the acknowledgment number field is used. If no flag, Sequence Number field refers to the first byte of data in that segment, receiver uses that number to place the data correctly in its reassembly buffer and to detect missing or out-of-order bytes.
    
    IF care abt latency use UDP, creation and teardown of conenctions in TCP takes a while.

# LECTURE 18: Transport Layer: Connection Managemetn + reliability
    
    server starts listening passively before sending syn state, client recieves the syn and sends syn/ack  and connection established. 
    when both decide they send syn simultaneously, they send syn + ack to each other and connection established. almost never prevered(happenes rarely). TCP therefore said to be assymetric connection.
    
    recieved fin, acknowledged for the fin client close, server sends fin, waits, recieves ack, waits again long time, close.
    both send fin at same point, both send ack, closing waiting to recieve ack, here both wait for a long time, then close.

    4 way to 3 way connection: client combined sending fin send and ack send into one.

    all this is very slow, so if app is latency sensitive do UDP.

    Sumary - TCP connection setup is assymetric, teardown is symmetric both ahve to send fins and acks(but can argue not symmetric due to time wait). most state schedule a timeout-triggered when expected responses does not happen.

    SYN flood attack - client can bombard unlimited msgs for syn connection, server will try to send connections to each; standard behavior. server if naively implemented, server is overwhelmed - denial of service attack. (think how want to implement, if want to listen to all might make it too slow to move on to other states, so need to think carefully)


    Reliability:
        packets can be lost/dup/reordered during transmission, checksum not enough.

        Challnege no in network observability: soln - sender ask receiver to ack every segment it sends, receiver can also check if bytestream misses any seg though sequence numbers(incremented by payload size not payload num).
        
        sender side detection - timeout, if sender does not receive ack after a timer per segment, start a timeout, if time runs out send it again.
            Use RTT estimaation - moving average of measured RTT, EWMA - exponentially weighted moving average(naive can also work). Timeout can be constant(i.e.2) times Estimated RTT

        receiever side stream of segents they recieve, 1.if missing segments in a small window- sry sender has to send it again:same longer waits, or 2. apply timeout again - implications to what app sees, low long, etc:i.e. longer wait times.
            sender must keep segment until recieves ack from receiever or timeout sned again. reciever can explicitly also for missing segment.

        Issue2: duplicated segment, easy to detect: look at seq number, not alterable, not affectable. if receive duplicates just reject it.

        Issue 3: next class.

# LECTURE 19: Transport layer: Reliability(II) + Congestion(I)

        Issue 3: out of order segment, if there is a hole in the data, might be out of order receieveing after the hole.
            can say strintly no to outof order segment, sender forced to retransmit. simple check bytestream seq to see if next byte  right seq.

            causes: congestion, comms paths become heterogeneous. similar to missing daata .

        Issue 4: Receiver Overwhelming, if buffers are getting full really fast, east to track.
            ask sender to slow down explicitly, and by how much exactly, 

        TCP mandatory to do sliding window, sending continously one after the other, addeses above issues. 
            app writes at the end, recerver reads at beg. sliding window increments by how much byte sent(based on MTU, etc - sent based on intervals selected like 1500 bytes.)
            everything behind next btye expected is in order, beyond may or maynot be TCP works to put them in order or drop, based on implementation. (so if deciede not to drop, does it become sequential async process? - i think abstracted away from app, kernel yes, but not necessarily from app cna be random)
            kernel buffers given by OS used to communicate between computers(TCP happens here), App buffer just reads last byte to read in kernel buffer.
            for everything sent we have an expected timeout to hear an acknowledgment back, if timeout without ack, we take it and make a copy and but bback at front on buffer and send again.
            TCP windows update only if next sequences are in order, available pointer to read jumps to end. order beyond the window handles by TCP to ensure order or OS dev keeping random holes, sorting, etc.
            now can detect duplicate and drop or missing, out of order if dont collapse or gap then know out of order(implementateion fix based on us), if nextbytetoread is getting to big to read need to tell sender to go slow or will be full so we send advertWindow = maxrecbuff - nextbyteexpected-1-lastbtyeread communicatng how slow recieving app is reading info .

        
        TCP flow control - sender controls transmission rate, looks at the num of msgs waiting to be acked is lesser than advertised window - called effective window. app speed is throttled.
            always happening, waits for more space on send buffer, and recieve buffer then send. continous process of speed up or slowdown.

        Resource Managemen: the underlying network fabric and hardware are dynamic,  we dont know how many apps use the network and their reqs.
            sender needs to be smart, rest can be dub - sender adjusts sending window baed on congestion signals(an event telling network contention **might** happen) from reciever.
                congestion window similar to sending window, choose minimum of all adv window and current congestion window. define total data sender can push to network. 
                optional MSS(Segmentsize), smallest invidivisble unit. default set if not chosen

            option 1: adv window from receiver, but can ovewhelm the network routers maybe.
            2: can randomly choose 0-adwindow, agian might overwhelm sometimes network routers.
            3. just make window size 1, very conservative but keeps data pipe moving.

            case 1 - recevve ack w/o timeout, effective BW = seg size/RTT, congestion window might be more than 1.
            case 2: dont gets acks 1 size might be limit.

            sender tries to find best size, from 1 to 2, 2-4 checks if working, in better tries more, if less tries less.(in order, both acts, no acks, out of order acks, etc.)
                when outoforder - some weak signal of congestion(can be strict and see it as strong), stong is no ack hearing at all.
            
            idea of doing exponential increase to find upper limit till you hit ceiling - TCP slow slart, no idea of rollback.
                outoforder then divide window by 2 or called congestion threshold = congestion window/2
                if local timeout congestion window turn into 1. go till last working size that worked exponentially then go linearly.

    What happens in TCP today next class.

# LECTURE 20: Transport Layer: Congestion(II)
    Acking strategies(reliability review):
        1. every acks get one packet (selective repeats)
        2. cumulative acks all packets up to a specifc packet (used in TCP)
        3. negative acks allows a reciever to ask for a packet that is presumed to be lost.(avoids delay with timeouts.)

    Basic go back n recovery - reciever drops packets out of order, sender sends packets after timeout and all other send in those timeouts(entire window).

    TCP Go Back N Variant(cumulative acks) - same as before, but sender sends past accepted ack only(accepting out of order, but sending last filled ack before out of order packet), sender just knows which packets were deleivered which werent. same as before send the window.
        Fast Retransmit( and then Timeout) - whenver you recieve 3 duplicate cumulative acks. you can innfer this is a strong signal that data 2 was never delievered. does not wait till end of timemout but sends data again.
            only useful for a few losses, if several better to go to timeout.
    
    SACK - (supported by TCP as optional) - uses bit masks. to acept what it can and retransmit what it couldnt?not sure

    congestion control:
        sender has control over window size also called congestion window size.
            utilization - each networking hardware is fully underutilized
            fairness - hardware is equally shared among other network users.
                multiplicative increase or decrease between two users: relative fairness is same, absolute fairness not(distance from fairness like increase.)
                additive: increase will imporve relative fairness, absolute fairness does not improve(improvement is perpendiculat to fairness line).

                idea is to promote fairness if someone starts late. need to stay under utilization curve, and closer to fairness line.
                    additive increase and multiplicative decrease - AIMD, i think its situation dependent, but said to be likely stable and bring you back to optimimal point regardless of where you start.(inaddition to slow start)

            
        congestion avoidance - start with slow start, once you first hit loss of pacets throttle by half, then do AIMD until optimal. for severe cases(back to 1 due to timeout) but exponential till prev max change's half, then AIMD.
            Fast Recovery - on 3 dup acks
                fast retransmit, MD : ss_thresh = cwnd/2. (we halve the full current window, not just the recent progress.)
                w = w+1 for each and every ack.(more dup acks mean not delievered but recieved some duplicates - you know what thing recieved in the bugger, so keep increasing size.) Once you start getting new acks we go back to w = w +1/w.

        congestion control: an ack indicates there is room to send data. 
        
        TCP Reno or any congestion algo uses slow start, aimd, fast retransmit/recovery, per-ack adjustment.
            (old implementation was TCP Tahoe - timeout(only method of congestion detection), slow start, AI. 3dup => cwd = 1, not effective)

                    
# Lecture 21: In-Network Support for TCP    
    
    Issue 1: silly window syndrome: sendner writing too slowly or reciever reding too slowly. too long hurt atency, too short, hurt bandwidth.
        Nagles Algo: a self-clocking soln: if both available data and window size >= MSS send the full segment, else: if there is unAcked data in flight buffer the new data until a ACK arrives, else send all the new data now.
        favors increasing latency (slow down dont waste bandwidth).
    
    Issue 2: timeout setwup during retransmissions
        dont know how to calculate timeout window, someitmes long due to ack coming long after retransmission, other times fast a few ms after retransmission sent.
        soln:when there is retransmission, dont do RTT, do 2x increase in timeout after each transmission. just a heyristic.

    TCP Modeling: Performance
        steady state, packets transferred = area under curve.
            bandwidth = 3/4 W * MSS/RTT, W is set when there is congestion(timeout, 3dup, etc - loss rate)
                1packet loss = loss rate = p  = 8/3W^2

        TCP is RTT fair

        TCO RENO bad for short lived conncections, Additive increase phase really slow (1.4 hrs). usually only realize 1/2 ish bandwidth.
            most file transfers are very small, tcp never reaches steady state - slow start dominates.
            TCP fairness is calculated on per flow basis.
                (some cheat by creating multiple flows, or maintain previous state)
            TLS is widely used adds 1-2 RTT transit(starts after tcp handshake)
            Google QUIC builds on top UDP, arguably better.
            but for long flows AIMD/TCP REno is better.
            
    In Network Support fot TCP:
        what can we do in network to make tcp faster.

        Active Queue Management(AQM): 
            enqueing rate > dequeing rate in router 
                packets get dropped if no space. space acts as a shock buffer.

            Naive approach - FIFO sheduling discipline. - Lock out problem(router full, other flow stuck at 1),
                we can do fair queing(FQ) - divide the buffer,virtual queues 1 for each flow. allocate resoruces more fairly. 
                    (can do Max-min fairness(round robin) now - divide underflows to serve uniformly to participants serving)
                        (can game system by sending variable sized packets. - do bit by bit Round robin that penalized large packets - uss finish times, arrival for last bit), only pickup packets by small FI(incentivises smaller packets)

# Lecture 22: In Network Support for TCP + Infrastructure Services.

            Random Early Detection(RED): detect incipient congestion
                maintains Weighted Moving Average (EWMA) que of length - filters out short-term bursts (noise) and focuses on long-term congestion.
                Traditionally (DropTail), we only drop when the buffer is completely full.
                    RED has min and max threshold. if avg <= min then does same as before Enqueue (accept). if avg >= max drop packets P = 1. avg in between Drop packet with some lower probability P early on much before buffer is full.
                good at keeping average queue length steady. allows gradual decay in performance, useful causse it allows us to do gradual decay in router congestion control as well, instead of Global Synchronization (where all TCP flows back off at the exact same time). It allows flows to back off individually.

            Explicit Congestion Notification(ECN): allows end to end notification of network congestion. every router starts talking and explicitly
                before congestion, while building up. routers send with some flag turned. and reciever only realizes some router realized congestion and send back to sender. (not every router creating same packet and notifying to reciever.)
                sender has to endable ECN in Terms of service header(IP TOS header) (00 - no ECN, 10/01 - sender is capable of ECN support, 11 - congestion encountered in router bit flipped) works for only if both parties support ECN.

        
        Reliable Link Layer: Packets are successfully delivered to the receiver.
           if no packets drops, dups, out of order. then do i still need end to end transport layer.

           reliable layer can handle packet drops.packet dups, out of order also handled by link layer.
                TCP control not as necessary. w/ caveat Link Layer only guarantees reliability across that specific link. not guarantee the packet won't be dropped by a buffer overflow at a router 3 hops away, or that the router won't crash and lose the packet.

            Ethernet is not reliable by default, so would always need some level of TCP control.

            TCP also allows measure of RTT of entire route(link only sees neighbor). Allows explicit feedback(ECN just an example, selective repeat, negative acks, etc.), (bandwidth probing, flow control, window adjustment - all these are good, without these need to figureout manally in link layer) 
                link layers a lot of packets will be dropped on steady state(introduce variable latency (jitter). If the link layer keeps trying to retransmit, the RTT estimate in TCP goes up, confusing the sender.), can work on complex application logic in meantime?
        
        Active Network
            a proposal that allows packets to carry programs. On-path entities can execute the logic.
            programmable network: every switch and router is capable of doing adaptation to packets. i.e. buffer management and queue management - round robin bit by bit, etc. has OS, progamming languages for them.
            SmartNIC: NICs with general purpose processors, domain-specific accelerators programmable DMA enginers, and SRAM/DRAM. (loadbalalncing efforts, switching, etc of Servers move to NIC - server has the NIC) examples: AWS nitro, AMD Pensando (DPU), etc.
                boom an Data Centers are happening in such Active Network areas, NICS, etc.

    
    Application Layer Serives(Infrastructure Services): also relavent to how networks run today.
        Domain Name Service (DNS); SNMP(Simple Network Management Protocol)

        technically an application layer program that is running.
        DNS motivation: Naming host. google.com converts to 32bit(IPv4) & 128bit(IPv6) address 
            hard for humans to remember natural language; goal is human friendly names to hosts: but routing still needs IP, define and lookup the mapping between name and IP.
            before DNS we had naive approach locally, between english domain name and Ip. ensure consistency (copy paste) across entire internet. does not scale, but still useful for small scaled local networks. (look at /etc/hosts file on CS dept machine)
            DNS is the distributed name resolution system, many name servers(NSs) are distributed throughout the internet,(UW madison entity hosts name servers, google themselves, etc.)
                Domain names(DNs) are hierarchical, a single NS doesnt need to store the name for eveery host of the internet. specific to org and suborg are deployed in a tree like structure.
                DNs can be mapped to IPV/4IPv6 and other DNS.
                queries are issued to a seq of NSs, each knows abt a different part of DN hierarchy, answers can be caached to avoid overhead of freq lookups.(typically start at root - everyone needs to know)

                the hierarchy starts from rightmost and periods separate them (cs.wisc.edu) edu topmost, cs bottom. DNs are processed right to left, period separator(no limit - unlike IP)
                    Top level domain(TLD) rightmost: edu,com,uk,info,ai, etc.
                    responsibility for resolution divided into zones: ICANN is responsible for the zone containing all TLDs, redundantly stored. not a single server, multiple server. (NSs cache name resolutions too name-ip)
                    Records: every NS only stores only its level and next level and TTL(freshness). is type is A = IPv4, AAAA = IPv6, NS = not directly the adress of next host, dom name for next DNS hierary.
                
                name resolution ALgo:
                not a one shot algorithm, hierarchical algo - client contacts the root name server (client contacts local name server which is given by DHCP router or set in its config, local NS constacts the root name server then the TLD, etc.)
                root ns provided the NS, a record for NS that can resolve TLD.
                local NS contacts the NS for TLD.
                NS for TDL provides NS, a record for NS that can resolve SLD
                local NS contacts NS for SLD
                NS for SLD provided a record for the domain or NS, a record for NS that can resolve the domain
                can have local DNS server network chokepoint/exit of network which will cache any records it recieved - to avoid frequent requests to root and tree traversal.

                Name Resolution Opimization: Load balaning(often achieved via CDNs content delivery networks) - assign short TTL to records, return different A records for each query for DN, Cycle through A records in weighted round robin order, weight based on server load.
                    geo location based server selection - alot servers closest to client. used by Content delivery networks.  lowest latency, highest bandwidth. google.com will have several ips geo location based for this.

        Why SNMP? network management essentially. (also application level protoval should work on every thing, TCP or wifi, etc.)
            track all devices that are connected, fault managemnt, diagnostic questiosn: load, how well balancing, etc.
            not specific to network topology, etc. should be standardized, extensible, portable.
            each device/agent has its local data. center server also has all data so other agents can query printer data, etc. some level of expose information exposure(how many color printers in my network,etc.).

            only has 5 commands. central server has: get-reqeust(fetch a val), get-next-request(ftch next val in tree), get-response(reply to fetch op), set-request(store val), Agent (Device/Router): trap(an event) (A "Trap" is an unsolicited alarm sent by the router to the server (e.g., "I just rebooted!" or "Link went down!").)

            The SNMP client pull, server push architechture. 

            runs on UDP, UDP Port 161: Used by the Agent to receive requests (Polling). UDP Port 162: Used by the Manager to receive Traps (Notifications).

# LECTURE 23: Application Layer in TCP/IP 
    ** might have some inconsistencies ** - Lecture went really quick

    apps can only requst tcp/usd, netwok conditions etc are not shared.
        app layer resp of taking account of uncertainty of data arriving.
        coordination logic for app to app.    

    Web/HTTps
        inspired by hytertex, doc linking another doc.

    Web
        a uniform resource locator: specify loc of an obj, perform dns lookups to obtain the ip addr of the web serter to contact.
        clients and web servers communicate using HTTP.
    
    HTTP(hypertext transfer protocol)
        underlying network: a reliable ocmms pipe with arb bandwidth - runs atop of TCP.
        plain text msgs in a req/resp seq; lines terminated by /r/n.

    
    fetching a webpage(or some data - http 1.0) - DNS lookup - Establish TCP connection - SEND HTTP req - recieve HTTP reply - Close TCP conn- Parse HTML
        closing expensie process both client and server needs to agree.
        for /web/obj extra paths, read DNC, open tCP sendreq&recieve close tcp, parse.

        problem high overheads, each obj 2 RTTS for connec setup + min 1 RTT for fetting and 2RTT again for teardown. (overhead reduced for large files open and close take smaller perctange of total RTT)
            never hit peak performance if lived time short, since MSS start at 1 and slow start.

    1.1 - introduces persistent connections - may have more fetches or not, just keep it open.
        exchange multiple req/resp msg over same Cp cnnection. Pros: throughput, slow start occurs once.
        cons: no point keeping connections open for so long if 1 req per 10 mins. server has to dedicate resources to maintain each of open connections.
        throughput benefits far outweigh this overhead.
    
    more progress on demand versions, other improvements, etc 1.2,3,4 etc.

    P2Ps
        a peer to peer network allows a community of users to pool thier resources.(storage,cpu,etc)
        (before client,server here just peers)
        p2p networks are decentralized and self organizing.
        no particular entity manages p2p networks. (1 peer down does not mean overall network down, google server down its down) - no reliable throughput? unclear who pays who.

        example BitTorrent - p2p file sharing protocol based on replicating the file or rather replicating segments off the file called pieces of chunks
            any particular piece can usually be downloaded from ultiple peers, even f only one peer has the entire file.
            avoid bottleneck of having only one source for a file, i.e. does need to wait for que for 1 single server maxed out, p2p looks for distributed nature.
                cons: to help some one else at your cost, no gurantee, etc. but flourished when everyone is active.
            todays world with economic incentives, p2p is not used (not easily observable,etc)

        execution logic: if you download you have to participate in uploading. more downlading more replication occurs - distribute load proportionally.
            pieces are downloaded in random order to avoid a situatio n where peers find themselves lacking the same set of pieces.
        
        coordination logic: swarms 
            each file is shared via its own indep network called swarms
            the swarm starts as a single pers with compelete copy of the file, a note wants todownload the file and join the swarm becoming 2nd mmber, downloading makes it another source,and other members can .
            1. P joins the swarm, 2 a tracker(distributed algo-runs partially on each p no server) replies tot P with partial list of peers, 3&4. P established CP connection with swarm ID. 
            5. each peers begins by sending bitmaps(what has vs not) of blocks it has. this is used by p to decide what block to get. 6. when downloading is finished bitmaps are eexchanged with all connected peers. 
            7.peers download blaocks in a random order to avoid getting bloaced on the smae place.

        cryptocurrency is also in the p2p world.


    comms bottle nets:
        first mile: client to ISP
        last mile: server to ISP
        server: compute/memory limitations
        isp: interconnections or peering congestion inside the network.
        solution: caching at various locations to overcome the latter three bottlenecks to lwoer the loads at other costs
        1st one cannot be helped(client side needs good link to isp, etc.)

    Proxy Chaches and CDN:
        limitations of web caching, much content is not cachable - like dynamic data, cookies, ssl, analystics.
        CDN.


#Guest Lectue IPv6 and WiscNetIMC, 
    cool stuff: IPvFOO
    https://www.wiscnet.net
    https://research.wiscnet.net/WiSciFest/
        https://test-ipv6.com/
    all giants google,cloudfare, amazon apple meta, etc on ipv6
    
        happy eyeballs tester to use more modern networks - test on app layer.

# LECTURE 24: 

    Caching at various locs to overcome the last mile(server to ISPP), server(compute/mem limitations), isp interconnections or peer to peer(congestion inside the network), but first mile(client to isp) cannot be helped.

    p2p helps reduce burden on each peer vs a single server but it has some pros and cons.

    continusing from last lec:

    App3: Proxy Caches and CDNs.
        Cache close to the client - under admin control of the client side AS.

            explicit proxy - req config the browser

            implicit prox - service providers deploy on on-path proxy. intercept and handle web requests.

        limitations: much content is not cacheable - caching policy
            static good but dynamic not great(most will be cache miss).
                stale data gets evicted by some polciy.

        CDN:
            proactive content replication - content provider contracts with a CDN
        
        seerver selection:
            live server - for availability
            lowest load - to balance the load across servers
            closest - nearest geo, or in round trip time.
            best - performe - throughput, latency.
            cheapest bandwidth, electricity, etc.
            (requires continous monitoring of liveness, load and performance.)

            Server selection mechanish - 
                app does http redirection. (redirects to another server based on above policy, gores to original then redirected.)
                    pros - fine grained, Cons - expensive
                naming. - dns based server selection (single subdomain can have multiple options, gives closes to you geographically and least crowded. DNS already has it)
                    pros - avoid tcp set up delays, dns caching reduces overheads, relaively fine control. Cons - based on ip addr of local DNS server, DNS TTL limits adoption.
    what are the learened elssions on building network apps.
        3 apps (web/HTTP),P2p(i.e. skype running on background to run someone elses work - idle mahcines participated for resharing(thus free) - Zoom is not p2p, its client-server arch), CDN and webcaching.

    security - important, transport layer secury(TLS-cryptocurrency-prime factoring algorithm) and HTTP(s - s is security) - didnt get to cover but is very important.
    
    Course Objectives highlevel Review:
        Fundamentals of Computer Networks
            Key takeaways:
                layering -> complexity
                Hierarchy -> Scalability
                End-to-End -> labor of division
                Mechanism and policy -> flexibility
        Develop small-scale network apps
            Key Takeaways:
                App representation
                Transport protocol selection
                Application specific optimization to enable better transport protocol
        Evaluate design trade-offs of networked systems
            Key Takeaways:
                Network performance depends on the compute efficiency
                the decentralization as the first requiremetn when designing protocols
                dont forget packet headers and channel/flow in-network states

    Where next steaps heading:
        most things happening phycal layer.(Satellite networks-exponentially growing, monopoly - BGP starts getting iteresting). 
        PHY+MAC: 5G,7G,etc
        transport layer a lot of developments happeing(QUIC)
        App: vehicular, mixed reality, internet of everything.
        Quantum Netoworking(quantum can break prime factoring algorithm  - how to secure, etc.(madison to chicago, upstate-building quantum networks already)).

End of Course Lectures.
Course: No public page available, checkout CS640 offering on UW-Madison (Most of the mathematical formulas/calculations not covered in txt notes.).    
    Next Course Progression adviced: CS707-Wireless Networking, CS740-Advanced Computer Networks, CS839: Big Ideas in Wireless(Akash teaching next sem)
